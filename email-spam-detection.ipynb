{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"top\"></a>\n<div style=\"text-align: center; background: #ff8c00; font-family: 'Montserrat', sans-serif; color: white; padding: 15px; font-size: 30px; font-weight: bold; line-height: 1; border-radius: 20px 20px 0 0; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2);\">üöÄ SMS Spam Classification: Detecting Unwanted Messages üöÄ</div>\n<div style=\"text-align: center;\">\n    <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*mbFBPcPUJD-53v3h.png\">\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background: #1ED760; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">Life Cycle of the Project</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-size: 14px; font-family: Verdana; border: 2px solid #ccc; background-color: #F5F5F5; padding: 10px; border-radius: 10px; margin-bottom: 20px; position: relative;\">\n\n  <!-- Add the image inside the div, aligned to the right-center -->\n   <img src=\"https://media.giphy.com/media/2lQzj96U6fb5qbknOW/giphy.gif\" style=\"position: absolute; left:40%; right: 0; transform: translateY(-50%); width: 200px; height: auto;\">\n   <img src=\"https://media.giphy.com/media/2lQzj96U6fb5qbknOW/giphy.gif\" style=\"position: absolute; left:60%; right: 0; transform: translateY(-50%); width: 200px; height: auto;\">\n    \n  <span style=\"color: #FF5733; font-weight: bold;\">Steps to be Performed</span>\n  <ol>\n    <li><a href=\"#1\">Introduction</a></li>\n    <li><a href=\"#2\">Problem Statement üôã</a></li>\n    <li><a href=\"#3\">Data Checks to Perform üîç</a></li>\n    <li><a href=\"#4\">Data Cleaning üßπ</a></li>\n    <li><a href=\"#5\">EDA üìä</a></li>\n    <li><a href=\"#6\">Text Preprocessing ‚úçÔ∏è</a></li>\n    <li><a href=\"#7\">Model Training ü§ñ</a></li>\n    <li><a href=\"#8\">Evaluation üìà</a></li>\n    <li><a href=\"#9\">Conclusion üéâ</a></li>\n    <li><a href=\"#10\">Author Message ‚úâÔ∏è</a></li>\n  </ol>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<div style=\"text-align: center; background: #1ED760; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">1. Introduction</div>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size: 14px; font-family: Verdana; background-color: #F5F5F5; border: 2px solid #ccc; padding: 10px; border-radius: 10px; display: inline-block;\">\n  This Kaggle notebook presents a step-by-step guide to building an efficient SMS <span style=\"background-color: #FF5733; color: white; font-weight: bold; padding: 3px 6px; border-radius: 3px;\">spam</span> classification model using the SMS Spam Collection dataset. By the end of this notebook, you'll have a powerful tool to help you filter out unwanted messages and ensure that your text messaging experience is smoother and safer.\n</span>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<div style=\"text-align: center; background: #1ED760; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">2. Problem Statement</div>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size: 14px; font-family: Verdana; border: 2px solid #ccc;background-color: #F5F5F5; padding: 10px; border-radius: 10px; display: inline-block; margin-bottom: 20px;\">\n  The primary goal of this notebook is to develop a predictive model that accurately classifies incoming SMS messages as either <span style=\"background-color: #FF5733; color: white; font-weight: bold; padding: 3px 6px; border-radius: 3px;\">ham</span> or <span style=\"background-color: #FF5733; color: white; font-weight: bold; padding: 3px 6px; border-radius: 3px;\">spam</span>. We will use the SMS Spam Collection dataset, which consists of 5,574 SMS messages tagged with their respective labels.\n</span>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<div style=\"text-align: center; background: #1ED760; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">3. Data Checks to Perform üîç</div>","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">3.1 Import Necessary Libraries</div>\n","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np        # For numerical operations\nimport pandas as pd       # For data manipulation and analysis\nimport matplotlib.pyplot as plt  # For data visualization\n%matplotlib inline\n\n# Importing WordCloud for text visualization\nfrom wordcloud import WordCloud\n\n# Importing NLTK for natural language processing\nimport nltk\nfrom nltk.corpus import stopwords    # For stopwords\n\n\n# Downloading NLTK data\nnltk.download('stopwords')   # Downloading stopwords data\nnltk.download('punkt')       # Downloading tokenizer data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">3.2 Load the Data</div>\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styled_df = df.head()\nstyled_df = styled_df.style.set_table_styles([\n    {\"selector\": \"th\", \"props\": [(\"color\", 'black'), (\"background-color\", \"#FF00CC\")]}\n])\nstyled_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">4. Data Cleaning</div>\n","metadata":{}},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.1 | Data Info</b></span>","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.2 | Drop the Columns</b></span>","metadata":{}},{"cell_type":"code","source":"df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styled_df = df.head(5).style\n\n\n# Modify the color and background color of the table headers (th)\nstyled_df.set_table_styles([\n    {\"selector\": \"th\", \"props\": [(\"color\", 'Black'), (\"background-color\", \"#FF00CC\"), ('font-weight', 'bold')]}\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.3 | Rename the Column</b></span>","metadata":{}},{"cell_type":"code","source":"  # Rename the columns name\ndf.rename(columns = {'v1': 'target', 'v2': 'text'}, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.4 | Convert the target variable</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndf['target'] = encoder.fit_transform(df['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styled_df = df.head().style\n\n\n# Modify the color and background color of the table headers (th)\nstyled_df.set_table_styles([\n    {\"selector\": \"th\", \"props\": [(\"color\", 'Black'), (\"background-color\", \"#FF00CC\"), ('font-weight', 'bold')]}\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.5 | Check Missing values</b></span>","metadata":{}},{"cell_type":"code","source":"#checking missing values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.6 | Check Duplicate values</b></span>","metadata":{}},{"cell_type":"code","source":"#check duplicate values\ndf.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.7 | Remove Duplicate values</b></span>","metadata":{}},{"cell_type":"code","source":"#remove Duplicate\ndf = df.drop_duplicates(keep = 'first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>4.8 | Shape of the Dataset</b></span>","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">5. EDA</div>\n","metadata":{}},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.1 | Percentage of Ham and Spam</b></span>","metadata":{}},{"cell_type":"code","source":"values = df['target'].value_counts()\ntotal = values.sum()\n\npercentage_0 = (values[0] /total) * 100\npercentage_1 = (values[1]/ total) *100\n\nprint('percentage of 0 :' ,percentage_0)\nprint('percentage of 1 :' ,percentage_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Sample data\n# values = [75, 25]  # Example values for 'ham' and 'spam'\n\n# Define custom colors\ncolors = ['#FF5733', '#33FF57']\n\n# Define the explode parameter to create a gap between slices\nexplode = (0, 0.1)  # Explode the second slice (spam) by 10%\n\n# Create a figure with a white background\nfig, ax = plt.subplots(figsize=(8, 8))\nax.set_facecolor('white')\n\n# Create the pie chart with custom colors, labels, explode parameter, and shadow\nwedges, texts, autotexts = ax.pie(\n    values, labels=['ham', 'spam'],\n    autopct='%0.2f%%',\n    startangle=90,\n    colors=colors,\n    wedgeprops={'linewidth': 2, 'edgecolor': 'white'},\n    explode=explode,  # Apply the explode parameter\n    shadow=True  # Add shadow\n)\n\n# Customize text properties\nfor text, autotext in zip(texts, autotexts):\n    text.set(size=14, weight='bold')\n    autotext.set(size=14, weight='bold')\n\n# Add a title\nax.set_title('Email Classification', fontsize=16, fontweight='bold')\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax.axis('equal')\n\n# Show the pie chart\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you see to the graph the percentage of ham is too high (87.37%) as compare to spam messages percentage. so the data is imbalance","metadata":{}},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.2 | Text Length and Structure Analysis</b></span>","metadata":{}},{"cell_type":"code","source":"df['num_characters'] = df['text'].apply(len)\ndf['num_words'] = df['text'].apply(lambda x: len(nltk.word_tokenize(x)))\ndf['num_sentence'] = df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['num_characters', 'num_words', 'num_sentence']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.3 | Summary Statistics for Legitimate Messages</b></span>","metadata":{}},{"cell_type":"code","source":"#ham\ndf[df['target'] == 0][['num_characters', 'num_words', 'num_sentence']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.4 | Summary Statistics for Spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"#spam\ndf[df['target'] == 1][['num_characters', 'num_words', 'num_sentence']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.5 | Character Length Distribution for Legitimate and Spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a figure and set the figure size\nplt.figure(figsize=(10, 6))\n\n# Plot the histogram for target 0 in blue\nsns.histplot(df[df['target'] == 0]['num_characters'], color='blue', label='Target 0', kde=True)\n\n# Plot the histogram for target 1 in red\nsns.histplot(df[df['target'] == 1]['num_characters'], color='red', label='Target 1', kde=True)\n\n# Add labels and a title\nplt.xlabel('Number of Characters', fontsize=14)\nplt.ylabel('Frequency', fontsize=14)\nplt.title('Distribution of Number of Characters by Target', fontsize=16, fontweight='bold')\n\n# Add a legend\nplt.legend()\n\n# Customize the appearance of the plot\nsns.set(style='whitegrid')  # Add a white grid background\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.6 | Word Count Distribution for Legitimate and Spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a figure and set the figure size\nplt.figure(figsize=(10, 6))\n\n# Plot the histogram for target 0 in blue\nsns.histplot(df[df['target'] == 0]['num_words'], color='blue', label='Target 0', kde=True)\n\n# Plot the histogram for target 1 in red\nsns.histplot(df[df['target'] == 1]['num_words'], color='red', label='Target 1', kde=True)\n\n# Add labels and a title\nplt.xlabel('Number of Words', fontsize=14)\nplt.ylabel('Frequency', fontsize=14)\nplt.title('Distribution of Number of Words by Target', fontsize=16, fontweight='bold')\n\n# Add a legend\nplt.legend()\n\n# Customize the appearance of the plot\nsns.set(style='whitegrid')  # Add a white grid background\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.7 | Pairplot for Data Visualization</b></span>","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a pairplot with custom styling\nsns.set(style='ticks', color_codes=True)\ng = sns.pairplot(df, hue='target', diag_kind='kde', markers=[\"o\", \"s\"])\n\n# Set a title for the pairplot\ng.fig.suptitle(\"Pairplot of Data by Target\", fontsize=16, fontweight='bold')\nplt.subplots_adjust(top=0.95)  # Adjust the position of the title\n\n# Customize the legend\ng._legend.set_title('Target')\nfor t, l in zip(g._legend.texts, [\"Target 0\", \"Target 1\"]):\n    t.set_text(l)\n\n# Show the pairplot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>5.8 | Coorelation</b></span>","metadata":{}},{"cell_type":"code","source":"df[['target','num_characters', 'num_words', 'num_sentence']].corr()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Select the columns for the correlation matrix\ncorrelation_matrix = df[['target', 'num_characters', 'num_words', 'num_sentence']].corr()\n\n# Create a heatmap with custom styling\nplt.figure(figsize=(10, 6))\nsns.set(font_scale=1.2)  # Adjust font scale for better readability\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt=\".2f\")\n\n# Set a title for the heatmap\nplt.title(\"Correlation Heatmap\", fontsize=16, fontweight='bold')\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Show the heatmap\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">6. Data Preprocessing</div>\n","metadata":{}},{"cell_type":"code","source":"# Importing the Porter Stemmer for text stemming\nfrom nltk.stem.porter import PorterStemmer\n\n# Importing the string module for handling special characters\nimport string\n\n# Creating an instance of the Porter Stemmer\nps = PorterStemmer()\n\n# Lowercase transformation and text preprocessing function\ndef transform_text(text):\n    # Transform the text to lowercase\n    text = text.lower()\n    \n    # Tokenization using NLTK\n    text = nltk.word_tokenize(text)\n    \n    # Removing special characters\n    y = []\n    for i in text:\n        if i.isalnum():\n            y.append(i)\n            \n    # Removing stop words and punctuation\n    text = y[:]\n    y.clear()\n    \n    # Loop through the tokens and remove stopwords and punctuation\n    for i in text:\n        if i not in stopwords.words('english') and i not in string.punctuation:\n            y.append(i)\n        \n    # Stemming using Porter Stemmer\n    text = y[:]\n    y.clear()\n    for i in text:\n        y.append(ps.stem(i))\n    \n    # Join the processed tokens back into a single string\n    return \" \".join(y)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>6.1 | Creating a New Column: 'transformed_text'</b></span>","metadata":{}},{"cell_type":"code","source":"df['transformed_text'] = df['text'].apply(transform_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"styled_df = df.head(5).style\n\n\n# Modify the color and background color of the table headers (th)\nstyled_df.set_table_styles([\n    {\"selector\": \"th\", \"props\": [(\"color\", 'Black'), (\"background-color\", \"#FF00CC\"), ('font-weight', 'bold')]}\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>6.2 | Word Cloud for Spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"wc = WordCloud(width = 500, height = 500, min_font_size = 10, background_color = 'white')\nspam_wc = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep = \" \"))\nplt.figure(figsize = (15,6))\nplt.imshow(spam_wc)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>6.2 | Word Cloud for Not spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"ham_wc = wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep = \" \"))\nplt.figure(figsize = (15,6))\nplt.imshow(ham_wc)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>6.3 | Find top 30 words of spam</b></span>","metadata":{}},{"cell_type":"code","source":"spam_carpos = []\nfor sentence in df[df['target'] == 1]['transformed_text'].tolist():\n    for word in sentence.split():\n        spam_carpos.append(word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nfilter_df = pd.DataFrame(Counter(spam_carpos).most_common(30))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data = filter_df, x = filter_df[0], y = filter_df[1], palette = 'bright')\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>6.4 | Find top 30 words of Not spam Messages</b></span>","metadata":{}},{"cell_type":"code","source":"ham_carpos = []\nfor sentence in df[df['target'] == 0]['transformed_text'].tolist():\n    for word in sentence.split():\n        ham_carpos.append(word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filter_ham_df = pd.DataFrame(Counter(spam_carpos).most_common(30))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data = filter_ham_df, x = filter_ham_df[0], y = filter_ham_df[1], palette = 'cool')\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<div style=\"text-align: center; background: linear-gradient(to right, #FF00CC, #660066); font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">7. Model Building</div>\n","metadata":{}},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.1 | Initializing CountVectorizer and TfidfVectorizer</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ncv = CountVectorizer()\ntfid = TfidfVectorizer(max_features = 3000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.2 | Dependent and Independent Variable</b></span>","metadata":{}},{"cell_type":"code","source":"X = tfid.fit_transform(df['transformed_text']).toarray()\ny = df['target'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.3 | Split into Train and Test Data</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.4 | Import the Models</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.5 | Initialize the Models</b></span>","metadata":{}},{"cell_type":"code","source":"svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\nknc = KNeighborsClassifier()\nmnb = MultinomialNB()\ndtc = DecisionTreeClassifier(max_depth = 5)\nlrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\nrfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\nabc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\nbc = BaggingClassifier(n_estimators = 50, random_state = 2)\netc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\ngbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \nxgb  = XGBClassifier(n_estimators = 50, random_state = 2)\n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.6 | Dictionary of the Models</b></span>","metadata":{}},{"cell_type":"code","source":"clfs = {\n    'SVC': svc,\n    'KNN': knc,\n    'NB': mnb,\n    'DT': dtc,\n    'LR': lrc,\n    'RF': rfc,\n    'Adaboost': abc,\n    'Bgc': bc,\n    'ETC': etc,\n    'GBDT': gbdt,\n    'xgb': xgb\n    \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> <span style='font-size:15px; font-family:Verdana;color: #FF00CC;'><b>7.7 |Train the Models</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score\ndef train_classifier(clfs, X_train, y_train, X_test, y_test):\n    clfs.fit(X_train,y_train)\n    y_pred = clfs.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    return accuracy , precision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">8. Evaluate the Models</div>\n","metadata":{}},{"cell_type":"code","source":"accuracy_scores = []\nprecision_scores = []\nfor name , clfs in clfs.items():\n    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n    print()\n    print(\"For: \", name)\n    print(\"Accuracy: \", current_accuracy)\n    print(\"Precision: \", current_precision)\n    \n    accuracy_scores.append(current_accuracy)\n    precision_scores.append(current_precision)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to the Top ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">9. Conclusion</div>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size: 14px; font-family: Verdana; background-color: #F5F5F5; border: 2px solid #ccc; padding: 10px; border-radius: 10px; display: inline-block;\">\n  <strong>Conclusion:</strong> In our evaluation of various classification algorithms, we observed the following key insights:\n\n  - Support Vector Classifier (SVC) and Random Forest (RF) demonstrated the highest accuracy, both achieving approximately <span style=\"background-color: yellow; font-weight: bold;\">97.58%</span>.\n  - Naive Bayes (NB) achieved a perfect precision score, indicating zero false positives.\n  - Other models, including Gradient Boosting, Adaboost, Logistic Regression, and Bagging Classifier, displayed competitive performance with accuracy scores ranging from <span style=\"background-color: yellow; font-weight: bold;\">94.68%</span> to <span style=\"background-color: yellow; font-weight: bold;\">96.03%</span>.\n\n  The selection of the optimal model should consider factors beyond just accuracy, such as computational efficiency and the specific requirements of the application. It is advisable to perform further model fine-tuning and validation before making a final choice.\n</span>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<div style=\"text-align: center; background:  #FF00CC; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 15px; font-size: 26px; font-weight: bold; line-height: 1; border-radius: 50% 0 50% 0 / 40px; margin-bottom: 20px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\">10. Author Message</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:white;font-size:15px;font-family:Georgia;border-style: solid;border-color: #FF00CC;border-width:3px;padding:10px;margin: 1px;color:#254E58;overflow:hidden\"> \n\n<h4><b style = 'color: red;'>Author :</b> Zabih ullah </h4>\n\n\n<b>üëâRead more project :</b> https://www.kaggle.com/zabihullah18 <br>\n<b>üëâShoot me mails :</b> zabihullah18381@gmail.com<br>\n<b>üëâConnect on LinkedIn :</b> https://www.linkedin.com/in/zabih-ullah/ <br>\n<b>üëâExplore Github :</b> https://github.com/Zabih-programs <br>\n    \n<hr>\n    \n<center> <strong> If you liked this Notebook, please do upvote. </strong>\n    \n<center> <strong> If you have any questions, feel free to comment! </strong>\n    \n<center> <strong style = 'color: red;' > ‚ú®Best Wishes‚ú® </strong>","metadata":{}}]}